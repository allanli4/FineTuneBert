{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8481,"status":"ok","timestamp":1702362622305,"user":{"displayName":"Zihao Zhao","userId":"07916579933323085958"},"user_tz":300},"id":"K-4doXNstrch","outputId":"9adeee74-11e6-4e60-eb87-2b240212c146"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: datasets in c:\\users\\gjk\\anaconda3\\lib\\site-packages (2.15.0)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\users\\gjk\\anaconda3\\lib\\site-packages (from datasets) (6.0)\n","Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\gjk\\anaconda3\\lib\\site-packages (from datasets) (14.0.1)\n","Requirement already satisfied: packaging in c:\\users\\gjk\\anaconda3\\lib\\site-packages (from datasets) (22.0)\n","Requirement already satisfied: xxhash in c:\\users\\gjk\\anaconda3\\lib\\site-packages (from datasets) (3.4.1)\n","Requirement already satisfied: numpy>=1.17 in c:\\users\\gjk\\anaconda3\\lib\\site-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pandas in c:\\users\\gjk\\anaconda3\\lib\\site-packages (from datasets) (1.4.4)\n","Requirement already satisfied: aiohttp in c:\\users\\gjk\\anaconda3\\lib\\site-packages (from datasets) (3.8.1)\n","Requirement already satisfied: huggingface-hub>=0.18.0 in c:\\users\\gjk\\anaconda3\\lib\\site-packages (from datasets) (0.19.4)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in c:\\users\\gjk\\anaconda3\\lib\\site-packages (from datasets) (0.3.7)\n","Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\gjk\\anaconda3\\lib\\site-packages (from datasets) (4.64.1)\n","Requirement already satisfied: multiprocess in c:\\users\\gjk\\anaconda3\\lib\\site-packages (from datasets) (0.70.15)\n","Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in c:\\users\\gjk\\anaconda3\\lib\\site-packages (from datasets) (2023.10.0)\n","Requirement already satisfied: pyarrow-hotfix in c:\\users\\gjk\\anaconda3\\lib\\site-packages (from datasets) (0.6)\n","Requirement already satisfied: requests>=2.19.0 in c:\\users\\gjk\\anaconda3\\lib\\site-packages (from datasets) (2.28.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\gjk\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.6.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\gjk\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\gjk\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\gjk\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.1)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\gjk\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.0.4)\n","Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\gjk\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (5.1.0)\n","Requirement already satisfied: attrs>=17.3.0 in c:\\users\\gjk\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: filelock in c:\\users\\gjk\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.18.0->datasets) (3.9.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\gjk\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.18.0->datasets) (4.7.1)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gjk\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gjk\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\gjk\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.14)\n","Requirement already satisfied: colorama in c:\\users\\gjk\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n","Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\gjk\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in c:\\users\\gjk\\anaconda3\\lib\\site-packages (from pandas->datasets) (2022.7)\n","Requirement already satisfied: six>=1.5 in c:\\users\\gjk\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\gjk\\appdata\\roaming\\python\\python39\\site-packages)\n","WARNING: Ignoring invalid distribution - (c:\\users\\gjk\\appdata\\roaming\\python\\python39\\site-packages)\n","WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\gjk\\appdata\\roaming\\python\\python39\\site-packages)\n","WARNING: Ignoring invalid distribution -orch (c:\\users\\gjk\\anaconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\gjk\\appdata\\roaming\\python\\python39\\site-packages)\n","WARNING: Ignoring invalid distribution - (c:\\users\\gjk\\appdata\\roaming\\python\\python39\\site-packages)\n","WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\gjk\\appdata\\roaming\\python\\python39\\site-packages)\n","WARNING: Ignoring invalid distribution -orch (c:\\users\\gjk\\anaconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\gjk\\appdata\\roaming\\python\\python39\\site-packages)\n","WARNING: Ignoring invalid distribution - (c:\\users\\gjk\\appdata\\roaming\\python\\python39\\site-packages)\n","WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\gjk\\appdata\\roaming\\python\\python39\\site-packages)\n","WARNING: Ignoring invalid distribution -orch (c:\\users\\gjk\\anaconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\gjk\\appdata\\roaming\\python\\python39\\site-packages)\n","WARNING: Ignoring invalid distribution - (c:\\users\\gjk\\appdata\\roaming\\python\\python39\\site-packages)\n","WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\gjk\\appdata\\roaming\\python\\python39\\site-packages)\n","WARNING: Ignoring invalid distribution -orch (c:\\users\\gjk\\anaconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\gjk\\appdata\\roaming\\python\\python39\\site-packages)\n","WARNING: Ignoring invalid distribution - (c:\\users\\gjk\\appdata\\roaming\\python\\python39\\site-packages)\n","WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\gjk\\appdata\\roaming\\python\\python39\\site-packages)\n","WARNING: Ignoring invalid distribution -orch (c:\\users\\gjk\\anaconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\gjk\\appdata\\roaming\\python\\python39\\site-packages)\n","WARNING: Ignoring invalid distribution - (c:\\users\\gjk\\appdata\\roaming\\python\\python39\\site-packages)\n","WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\gjk\\appdata\\roaming\\python\\python39\\site-packages)\n","WARNING: Ignoring invalid distribution -orch (c:\\users\\gjk\\anaconda3\\lib\\site-packages)\n"]}],"source":["!pip install datasets"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":234,"status":"ok","timestamp":1702365474898,"user":{"displayName":"Zihao Zhao","userId":"07916579933323085958"},"user_tz":300},"id":"nef1F9kktyuh"},"outputs":[],"source":["from datasets import load_dataset\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader, Dataset\n","from datasets import load_dataset\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","import string\n","from torch.utils.data import random_split\n","import numpy as np\n","\n","from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n","from transformers import get_linear_schedule_with_warmup\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":422562,"status":"ok","timestamp":1702364181064,"user":{"displayName":"Zihao Zhao","userId":"07916579933323085958"},"user_tz":300},"id":"EjgKPSzRt-Jl"},"outputs":[],"source":["label_columns = ['related', 'PII', 'request', 'offer', 'aid_related', 'medical_help',\n","                 'medical_products', 'search_and_rescue', 'security', 'military',\n","                 'child_alone', 'water', 'food', 'shelter', 'clothing', 'money',\n","                 'missing_people', 'refugees', 'death', 'other_aid', 'infrastructure_related',\n","                  'transport', 'buildings', 'electricity', 'tools', 'hospitals', 'shops',\n","                 'aid_centers', 'other_infrastructure', 'weather_related', 'floods', 'storm',\n","                 'fire', 'earthquake', 'cold', 'other_weather', 'direct_report']\n","num_labels = len(label_columns)\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","def preprocess_for_bert(data):\n","    # Tokenize the messages and prepare the labels\n","    input_ids = []\n","    attention_masks = []\n","    labels = []\n","\n","    for i in range(len(data)):\n","        encoded = tokenizer.encode_plus(\n","            data[i]['message'],\n","            add_special_tokens=True,\n","            max_length=128,  # Adjust as needed\n","            padding='max_length',\n","            truncation=True,\n","            return_attention_mask=True,\n","            return_tensors='pt',\n","        )\n","        input_ids.append(encoded['input_ids'])\n","        attention_masks.append(encoded['attention_mask'])\n","        labels.append([data[i][label] for label in label_columns])\n","\n","    input_ids = torch.cat(input_ids, dim=0)\n","    attention_masks = torch.cat(attention_masks, dim=0)\n","    labels = torch.tensor(labels, dtype=torch.float)\n","\n","    return input_ids, attention_masks, labels\n","dataset = load_dataset(\"disaster_response_messages\")\n","# Apply preprocessing\n","train_input_ids, train_attention_masks, train_labels = preprocess_for_bert(dataset['train'])\n","val_input_ids, val_attention_masks, val_labels = preprocess_for_bert(dataset['validation'])\n","test_input_ids, test_attention_masks, test_labels = preprocess_for_bert(dataset['test'])"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":345,"status":"ok","timestamp":1702366124637,"user":{"displayName":"Zihao Zhao","userId":"07916579933323085958"},"user_tz":300},"id":"jMf7-unGw-aW"},"outputs":[],"source":["from torch.utils.data import TensorDataset\n","\n","batch_size = 16\n","\n","# Create the DataLoader for our training set\n","train_data = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n","train_sampler = torch.utils.data.RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# Create the DataLoader for our validation set\n","validation_data = TensorDataset(val_input_ids, val_attention_masks, val_labels)\n","validation_sampler = torch.utils.data.SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n","\n","test_data = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n","test_sampler = torch.utils.data.SequentialSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1315,"status":"ok","timestamp":1702364436613,"user":{"displayName":"Zihao Zhao","userId":"07916579933323085958"},"user_tz":300},"id":"mN-HU1JzxDjH","outputId":"b60db67c-d46d-4292-acd2-bb6397759067"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=37, bias=True)\n",")"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":281,"status":"ok","timestamp":1702367002160,"user":{"displayName":"Zihao Zhao","userId":"07916579933323085958"},"user_tz":300},"id":"fi5f4anxxFnS","outputId":"dd641f52-b6ec-473f-e88f-1af6963dc5bf"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\GJK\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["optimizer = AdamW(model.parameters(), lr=5e-5)\n","epochs = 4  # Adjust as needed\n","total_steps = len(train_dataloader) * epochs\n","\n","scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                            num_warmup_steps=0,\n","                                            num_training_steps=total_steps)\n","loss_fn = torch.nn.BCEWithLogitsLoss()"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":337,"status":"ok","timestamp":1702366520799,"user":{"displayName":"Zihao Zhao","userId":"07916579933323085958"},"user_tz":300},"id":"I7zkUzLo80yp"},"outputs":[],"source":["def multilabel_accuracy(preds, labels, threshold=0.5):\n","    preds = torch.sigmoid(preds)\n","    preds = (preds > threshold).float()\n","    correct = (preds == labels).float()\n","    acc = correct.sum() / correct.numel()\n","    return acc\n","    accuracy = multilabel_accuracy(outputs.logits, batch_labels)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7178,"status":"ok","timestamp":1702367121105,"user":{"displayName":"Zihao Zhao","userId":"07916579933323085958"},"user_tz":300},"id":"WH0ZtyOr9PNm","outputId":"7fb22cde-b4f5-4403-c836-0f5855820760"},"outputs":[],"source":["def validate(model, dataloader, loss_fn, device):\n","    model.eval()\n","    total_loss, total_accuracy = 0, 0\n","\n","    for batch in dataloader:\n","        inputs, attention_masks, labels = batch[0].to(device), batch[1].to(device), batch[2].to(device)\n","\n","        with torch.no_grad():\n","            outputs = model(input_ids=inputs, attention_mask=attention_masks)\n","            loss = loss_fn(outputs.logits, labels)\n","            acc = multilabel_accuracy(outputs.logits, labels)\n","\n","        total_loss += loss.item()\n","        total_accuracy += acc.item()\n","\n","    avg_loss = total_loss / len(dataloader)\n","    avg_acc = total_accuracy / len(dataloader)\n","    return avg_loss, avg_acc\n","\n","\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":606542,"status":"ok","timestamp":1702368135906,"user":{"displayName":"Zihao Zhao","userId":"07916579933323085958"},"user_tz":300},"id":"KGjie40Vwncn","outputId":"35101bf8-e567-4cd4-9ac7-4a4ed754828c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/4 - Loss: 0.1217, Accuracy: 0.9576\n","Validation Loss: 0.12974161449935495, Validation Accuracy: 0.9545258872257256\n","Epoch 2/4 - Loss: 0.1023, Accuracy: 0.9642\n","Validation Loss: 0.12997588701546192, Validation Accuracy: 0.955483068960794\n","Epoch 3/4 - Loss: 0.0854, Accuracy: 0.9698\n","Validation Loss: 0.1389205928267159, Validation Accuracy: 0.9543991784871735\n","Epoch 4/4 - Loss: 0.0708, Accuracy: 0.9740\n","Validation Loss: 0.1498237234418807, Validation Accuracy: 0.95150181299411\n"]}],"source":["for epoch in range(epochs):\n","    model.train()\n","    total_loss, total_accuracy = 0, 0\n","\n","    for batch in train_dataloader:\n","        inputs, attention_masks, labels = batch[0].to(device), batch[1].to(device), batch[2].to(device)\n","        optimizer.zero_grad()\n","\n","        outputs = model(input_ids=inputs, attention_mask=attention_masks)\n","\n","\n","        loss = loss_fn(outputs.logits, labels)\n","        loss.backward()\n","        optimizer.step()\n","        acc = multilabel_accuracy(outputs.logits, labels)\n","\n","        total_loss += loss.item()\n","        total_accuracy += acc.item()\n","\n","\n","    avg_train_loss = total_loss / len(train_dataloader)\n","    avg_train_acc = total_accuracy / len(train_dataloader)\n","\n","\n","    print(f\"Epoch {epoch + 1}/{epochs} - Loss: {avg_train_loss:.4f}, Accuracy: {avg_train_acc:.4f}\")\n","\n","\n","    val_loss, val_accuracy = validate(model, validation_dataloader, loss_fn, device)\n","    print(f'Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5971,"status":"ok","timestamp":1702368208816,"user":{"displayName":"Zihao Zhao","userId":"07916579933323085958"},"user_tz":300},"id":"JNUXXbsg2zXE","outputId":"a60fbe54-282a-43d6-d3b2-ac5dc7a0cf03"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Loss: 0.12349298098547892, Test Accuracy: 0.9623628388751637\n"]}],"source":["def test(model, dataloader, loss_fn, device):\n","    model.eval()\n","    total_loss, total_accuracy = 0, 0\n","\n","    for batch in dataloader:\n","        inputs, attention_masks, labels = batch[0].to(device), batch[1].to(device), batch[2].to(device)\n","\n","        with torch.no_grad():\n","            outputs = model(input_ids=inputs, attention_mask=attention_masks)\n","            loss = loss_fn(outputs.logits, labels)\n","            acc = multilabel_accuracy(outputs.logits, labels)\n","\n","        total_loss += loss.item()\n","        total_accuracy += acc.item()\n","\n","    avg_loss = total_loss / len(dataloader)\n","    avg_acc = total_accuracy / len(dataloader)\n","    return avg_loss, avg_acc\n","\n","# Example usage after completing all training epochs\n","test_loss, test_accuracy = test(model, test_dataloader, loss_fn, device)\n","print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["torch.save(model.state_dict(), 'bert_model.pt')"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyP0XM/c4nlMM48dcYQUfi4n","gpuType":"V100","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}
